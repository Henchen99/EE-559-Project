{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 559 Project\n",
    "Ronald Huang & Henry Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "#import seaborn as sns\n",
    "from collections import Counter, deque\n",
    "\n",
    "\n",
    "# For Computing Priors\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# For Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# For Model Selection\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# For creating Tensorflow models\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.layers import Dense, Input, Dropout, SimpleRNN, GRU, LSTM, Conv1D\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# For plotting ROC and Precision Recall curves\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "# For OS agnostic path handling\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = np.loadtxt('data/FLIR_groups1and2_train.csv', delimiter = ',', skiprows = 2)\n",
    "# train = pd.read_csv('data/FLIR_groups1and2_train.csv')\n",
    "# test = pd.read_csv('data/FLIR_groups1and2_test.csv')\n",
    "\n",
    "\n",
    "data_path = 'data/FLIR_groups1and2_train.csv'\n",
    "\n",
    "read_train = pd.read_csv(data_path, skiprows = 2)\n",
    "train = read_train.iloc[:, 2:]\n",
    "\n",
    "\n",
    "\n",
    "round_1 = train.iloc[:, :26]\n",
    "round_2 = train.iloc[:, 28:55]\n",
    "round_3 = train.iloc[:, 56:83]\n",
    "round_4 = train.iloc[:, 84:111]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty(round):\n",
    "    empty_rows = []\n",
    "    \n",
    "    for i, row in round.iterrows():\n",
    "        if row.isnull().all():\n",
    "            empty_rows.append(i)\n",
    "            \n",
    "    return empty_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Rows in Row 1:  [17, 78, 132, 171, 236, 292, 413, 483, 593, 616, 662]\n",
      "Empty Rows in Row 2:  [22, 106, 171, 292, 413, 479, 609, 626, 686]\n",
      "Empty Rows in Row 3:  [22, 294, 386, 489]\n",
      "Empty Rows in Row 4:  [20, 76, 107, 113, 128, 187, 221, 236, 252, 272, 294, 325, 359, 414, 469, 484, 485, 560, 573, 639, 695]\n"
     ]
    }
   ],
   "source": [
    "round_1_empty_rows = find_empty(round_1)\n",
    "round_2_empty_rows = find_empty(round_2)\n",
    "round_3_empty_rows = find_empty(round_3)\n",
    "round_4_empty_rows = find_empty(round_4)\n",
    "\n",
    "print(\"Empty Rows in Row 1: \", round_1_empty_rows)\n",
    "print(\"Empty Rows in Row 2: \", round_2_empty_rows)\n",
    "print(\"Empty Rows in Row 3: \", round_3_empty_rows)\n",
    "print(\"Empty Rows in Row 4: \", round_4_empty_rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94230329 35.48566524 35.49520744 34.75422031 34.86494993 35.5460515\n",
      " 35.47298999 35.42725322 35.57602289 35.52307582 35.49018598 35.33283262\n",
      " 35.55513591 35.1376824  35.06958512 35.67031474 35.64042918 34.37835479\n",
      " 34.37904149 34.37323319 34.28218884 34.37639485 35.30287554 34.93545064\n",
      " 35.77281831 35.23891273]\n",
      "[ 0.94940086 35.56536377 35.56318117 34.87737518 34.97776034 35.61436519\n",
      " 35.55590585 35.49155492 35.64512126 35.59132668 35.56472183 35.41392297\n",
      " 35.62121255 35.21319544 35.15457917 35.73736091 35.70811698 34.54611983\n",
      " 34.5321826  34.53081312 34.4496291  34.55269615 35.39077033 35.05797432\n",
      " 35.94385164 35.69333809 35.72673324]\n",
      "[ 0.94648725 35.58427762 35.59314448 34.9382153  35.04140227 35.63968839\n",
      " 35.57073654 35.51511331 35.66936261 35.61243626 35.59015581 35.41324363\n",
      " 35.64195467 35.23888102 35.15695467 35.76186969 35.73325779 34.56661473\n",
      " 34.56022663 34.54790368 34.47818697 34.56185552 35.41555241 35.08413598\n",
      " 35.95050992 35.69991501 35.73481586]\n",
      "[ 0.94583697 35.61014514 35.62179971 34.88397678 35.0194775  35.67052402\n",
      " 35.60746725 35.5514556  35.69917031 35.65238719 35.62765648 35.46810771\n",
      " 35.68211063 35.25144105 35.21909753 35.80404658 35.77393013 34.59011645\n",
      " 34.56988355 34.56538574 34.51147016 34.60531295 35.36989811 35.05321689\n",
      " 36.56845706 36.50915575 36.53836972]\n"
     ]
    }
   ],
   "source": [
    "round_1_means = (round_1.mean()).values  #dtype is float64\n",
    "round_2_means = (round_2.mean()).values\n",
    "round_3_means = (round_3.mean()).values\n",
    "round_4_means = (round_4.mean()).values\n",
    "\n",
    "print(round_1_means)\n",
    "print(round_2_means)\n",
    "print(round_3_means)\n",
    "print(round_4_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_mean(round_num, empty_rows, mean):\n",
    "    rounds_final = round_num\n",
    "    \n",
    "    for i in empty_rows:\n",
    "        rounds_final.loc[i] = mean\n",
    "\n",
    "    return rounds_final\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_round_1 = insert_mean(round_1, round_1_empty_rows, round_1_means)\n",
    "final_round_2 = insert_mean(round_2, round_2_empty_rows, round_2_means)\n",
    "final_round_3 = insert_mean(round_3, round_3_empty_rows, round_3_means)\n",
    "final_round_4 = insert_mean(round_4, round_4_empty_rows, round_4_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_empty = find_empty(final_round_1)\n",
    "print(test_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intial Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relation Between Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data PreProcessing \n",
    "* Removing Outliers\n",
    "* Filling in missing data/balancing out the data\n",
    "* Feature Importance\n",
    "* Feature Extraction/Dimensionality Reduction\n",
    "* Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing data with means \n",
    "#calculate means and std of every feature for every round \n",
    "# normalize data\n",
    "\n",
    "#pandas describe\n",
    "#pandas fillna\n",
    "\n",
    "\n",
    "# 1. compute stats for each round (mean and std)\n",
    "# 2. if stats for each round are similar, fill in missing data with means\n",
    "# 3. concatenate in round order\n",
    "# 4. group by subject ID\n",
    "# 4.5. feature engineering\n",
    "# 5. shuffle wrt subject ID\n",
    "# 6. split k-fold into train and val (90% 10%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trivial Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Output Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression (No Regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-Class Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Nearest Neighbours Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-Class Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Long Short Term Memory Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
